{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse single structure (subtree) from K page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# It can be faster to get text and BR link in the same function, not implemented yet.\n",
    "\n",
    "def get_subtree_text(url):\n",
    "    \"\"\" \n",
    "    url like https://www.kegg.jp/entry/K02703 are from \n",
    "    >>> with open(pathway_gene_name_filename, 'r') as f:\n",
    "            gene_ids = []\n",
    "            for i in f.readlines():\n",
    "                gene_ids.append(i[:6])\n",
    "        urls = []\n",
    "        prefix = 'https://www.genome.jp/entry/'\n",
    "        for i in gene_ids:\n",
    "            urls.append(prefix+i)\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    webpage = response.content\n",
    "    gene_id = url[-6:]\n",
    "\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    for i in soup.find_all('span'):\n",
    "        if '\\xa0'+gene_id in i.text:\n",
    "            target = i\n",
    "    target = str(target).replace('\\xa0', ' ')\\\n",
    "    .replace('</span>', '').replace('<br/>', '')\\\n",
    "    .replace('<span class=\"nowrap\">', '').split('\\n')\n",
    "    root = TreeNode(None)\n",
    "    for i in target:\n",
    "        if i: # skip empty lines\n",
    "            depth = len(i) - len(i.lstrip(' ')) + 1\n",
    "            add_node(root, i.strip(), depth)\n",
    "    return root\n",
    "\n",
    "\n",
    "class TreeNode():\n",
    "    def __init__(self, value) -> None:\n",
    "        self.value = value\n",
    "        self.children = []\n",
    "\n",
    "\n",
    "def print_tree(node, level=0):\n",
    "    if node.value is not None:\n",
    "        try:\n",
    "            print('  ' * level + node.value)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"{node.value=}, {node.children=}\")\n",
    "            return\n",
    "    for child in node.children:\n",
    "        print_tree(child, level + 1)\n",
    "\n",
    "\n",
    "def add_node(root, value, depth):\n",
    "    current = root\n",
    "    \n",
    "    for _ in range(depth - 1):\n",
    "        if current.children:\n",
    "            current = current.children[-1]\n",
    "        else:\n",
    "            new_child = TreeNode(None)\n",
    "            current.children.append()\n",
    "            current = new_child\n",
    "    \n",
    "    new_node = TreeNode(value)\n",
    "    current.children.append(new_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"gene_link_K_page.pkl\", 'rb') as p:\n",
    "    urls = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [03:35<00:00,  3.43s/it]\n"
     ]
    }
   ],
   "source": [
    "gene_subtree_dic = {}\n",
    "\n",
    "for url in tqdm(urls):\n",
    "    gene_subtree_dic[url[-6:]] = get_subtree_text(url)\n",
    "\n",
    "with open(\"gene_subtree_dic.pkl\", 'wb') as p:\n",
    "    pickle.dump(gene_subtree_dic, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gene_subtree_dic.pkl\", 'rb') as p:\n",
    "    gene_subtree_dic_from_pkl = pickle.load(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse total structure (tree) from BR page (need to be finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_BR_url_from_k_page(k_url):\n",
    "    \"\"\" \n",
    "    url like https://www.kegg.jp/entry/K02703 are from \n",
    "    >>> with open(pathway_gene_name_filename, 'r') as f:\n",
    "            gene_ids = []\n",
    "            for i in f.readlines():\n",
    "                gene_ids.append(i[:6])\n",
    "        urls = []\n",
    "        prefix = 'https://www.genome.jp/entry/'\n",
    "        for i in gene_ids:\n",
    "            urls.append(prefix+i)\n",
    "    \"\"\"\n",
    "    response = requests.get(k_url)\n",
    "    webpage = response.content\n",
    "    gene_id = k_url[-6:]\n",
    "\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    for i in soup.find_all('span'):\n",
    "        if '\\xa0'+gene_id in i.text:\n",
    "            target = i\n",
    "    pattern = re.compile(r'BR:<a href=\"(.+?)\"')\n",
    "    links = pattern.findall(str(target))\n",
    "    return links\n",
    "\n",
    "def parse_BR_tree(data):\n",
    "    node = TreeNode(data.get('values', None))\n",
    "    for child_data in data.get('children', []):\n",
    "        child_node = parse_BR_tree(child_data)\n",
    "        node.children.append(child_node)\n",
    "    return node\n",
    "\n",
    "def clean_br_tree_dic(node):\n",
    "    # Basically convert lists in value into strings\n",
    "    if 'values' in node:\n",
    "        if isinstance(node['values'], list):\n",
    "            node['values'] = ''.join(node['values'])\n",
    "    \n",
    "    if 'children' in node:\n",
    "        for child in node['children']:\n",
    "            clean_br_tree_dic(child)\n",
    "\n",
    "def get_total_BR_link_tuple(urls):\n",
    "    br_links = set()\n",
    "    prefix = \"https://www.genome.jp\"\n",
    "    for i in tqdm(urls):\n",
    "        tmp_links = get_single_BR_url_from_k_page(i)\n",
    "        for j in tmp_links:\n",
    "            tmp_full_link = prefix + j\n",
    "            br_links.add(tmp_full_link)\n",
    "\n",
    "    total_BR_link = set()\n",
    "    for i in br_links:\n",
    "        total_BR_link.add(i[:-7])\n",
    "    \n",
    "    return br_links, total_BR_link\n",
    "\n",
    "def get_total_BR_tree_dic(br_links_tuple):\n",
    "    max_attempts = 5\n",
    "    total_BR_tree_dic = dict()\n",
    "    \n",
    "    for i in tqdm(list(br_links_tuple[1])):\n",
    "        current_attempt = 1\n",
    "        name = i[-7:]\n",
    "        while current_attempt <= max_attempts:\n",
    "            try:\n",
    "                br_tree = _get_single_BR_tree(i)\n",
    "                total_BR_tree_dic[name] = br_tree\n",
    "                break  # Exit the loop if the function runs without errors\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {current_attempt}: An error occurred - {str(e)}\")\n",
    "                time.sleep(1)\n",
    "                current_attempt += 1\n",
    "\n",
    "        if current_attempt > max_attempts:\n",
    "            print(f\"Max attempts reached. Function execution failed on page {i}.\")\n",
    "    \n",
    "    return total_BR_tree_dic\n",
    "\n",
    "def _get_single_BR_tree(br_url):\n",
    "    br_page = requests.get(br_url)\n",
    "    soup = BeautifulSoup(br_page.content, 'html.parser')\n",
    "    raw = str(soup.find_all('script')[-1]).split('\\n')[1][13:]\n",
    "    pattern = r'<a.*?a>'\n",
    "    dic_text = re.sub(pattern, '', raw)\n",
    "    replace_list = ['\"expanded\":false,', ',\"expanded\":false',\n",
    "            '\"expanded\":true,', ',\"expanded\":true',\n",
    "            '\"expanded\":true,', ',\"expanded\":true', ',\"isRoot\":true', '\"isRoot\":true,', '<b>', '</b>',\n",
    "            ',\"devMode\":false', ',\"columnWidth\":[]', ',\"visibleIndentHandle\":false', ',\"columnTitle\":[\"Chaperone\"]',\n",
    "            ',\"org\":\"ko\"', ',\"isIndexFile\":false', ',\"joinPruningQuery\":[]', ',\"alignTerminalNode\":false',\n",
    "            ',\"zoomout\":null', ',\"highlight\":{}', ',\"joinPruningColumn\":[]'\n",
    "            ',\"htextNo\":\"03110\"']\n",
    "    for i in replace_list:\n",
    "        dic_text = dic_text.replace(i, '')\n",
    "\n",
    "    dic_text = dic_text.replace('\"values\":[]', '\"values\": None').replace('\"values\": []', '\"values\": None')\n",
    "    tree_dic = eval(dic_text)\n",
    "    tree_dic = tree_dic['root']\n",
    "\n",
    "    clean_br_tree_dic(tree_dic)\n",
    "    br_tree = parse_BR_tree(tree_dic)\n",
    "    \n",
    "    return br_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_links, total_BR_link = get_total_BR_link_tuple(urls)\n",
    "br_links_tuple = br_links, total_BR_link\n",
    "with open(\"br_links_tuple.pkl\", 'wb') as p:\n",
    "    pickle.dump(br_links_tuple, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: An error occurred - name 'false' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:05<00:04,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 2: An error occurred - name 'false' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:26<00:10, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 3: An error occurred - name 'false' is not defined\n",
      "Attempt 4: An error occurred - name 'false' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:42<00:00, 10.61s/it]\n"
     ]
    }
   ],
   "source": [
    "total_BR_tree_dic = get_total_BR_tree_dic(br_links_tuple)\n",
    "with open(\"total_BR_tree_dic.pkl\", 'wb') as p:\n",
    "    pickle.dump(total_BR_tree_dic, p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
