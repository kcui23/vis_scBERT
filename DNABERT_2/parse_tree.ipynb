{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse single structure (subtree) from K page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from mytree import *\n",
    "\n",
    "# It can be faster to get text and BR link in the same function, not implemented yet.\n",
    "\n",
    "def get_subtree_text(url):\n",
    "    \"\"\" \n",
    "    url like https://www.kegg.jp/entry/K02703 are from \n",
    "    >>> with open(pathway_gene_name_filename, 'r') as f:\n",
    "            gene_ids = []\n",
    "            for i in f.readlines():\n",
    "                gene_ids.append(i[:6])\n",
    "        urls = []\n",
    "        prefix = 'https://www.genome.jp/entry/'\n",
    "        for i in gene_ids:\n",
    "            urls.append(prefix+i)\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    webpage = response.content\n",
    "    gene_id = url[-6:]\n",
    "\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    for i in soup.find_all('span'):\n",
    "        if '\\xa0'+gene_id in i.text:\n",
    "            target = i\n",
    "    target = str(target).replace('\\xa0', ' ')\\\n",
    "    .replace('</span>', '').replace('<br/>', '')\\\n",
    "    .replace('<span class=\"nowrap\">', '').split('\\n')\n",
    "    root = TreeNode(None)\n",
    "    for i in target:\n",
    "        if i: # skip empty lines\n",
    "            depth = len(i) - len(i.lstrip(' ')) + 1\n",
    "            add_node(root, i.strip(), depth)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"gene_link_K_page.pkl\", 'rb') as p:\n",
    "    urls = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [03:35<00:00,  3.43s/it]\n"
     ]
    }
   ],
   "source": [
    "gene_subtree_dic = {}\n",
    "\n",
    "for url in tqdm(urls):\n",
    "    gene_subtree_dic[url[-6:]] = get_subtree_text(url)\n",
    "\n",
    "with open(\"gene_subtree_dic.pkl\", 'wb') as p:\n",
    "    pickle.dump(gene_subtree_dic, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gene_subtree_dic.pkl\", 'rb') as p:\n",
    "    gene_subtree_dic_from_pkl = pickle.load(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  KEGG Orthology (KO) [BR:<a href=\"/brite/ko00001+K02108\">ko00001</a>]\n",
      "    09100 Metabolism\n",
      "      09102 Energy metabolism\n",
      "        00190 Oxidative phosphorylation\n",
      "          K02108  ATPF0A, atpB; F-type H+-transporting ATPase subunit a\n",
      "        00195 Photosynthesis\n",
      "          K02108  ATPF0A, atpB; F-type H+-transporting ATPase subunit a\n",
      "    09180 Brite Hierarchies\n",
      "      09181 Protein families: metabolism\n",
      "        00194 Photosynthesis proteins\n",
      "          K02108  ATPF0A, atpB; F-type H+-transporting ATPase subunit a\n",
      "      09182 Protein families: genetic information processing\n",
      "        03110 Chaperones and folding catalysts\n",
      "          K02108  ATPF0A, atpB; F-type H+-transporting ATPase subunit a\n",
      "  Photosynthesis proteins [BR:<a href=\"/brite/ko00194+K02108\">ko00194</a>]\n",
      "    Photosystem and electron transport system\n",
      "      F-type ATPase [OT]\n",
      "        K02108  ATPF0A, atpB; F-type H+-transporting ATPase subunit a\n",
      "  Chaperones and folding catalysts [BR:<a href=\"/brite/ko03110+K02108\">ko03110</a>]\n",
      "    Other chaperones and cochaperones\n",
      "      PapD\n",
      "        K02108  ATPF0A, atpB; F-type H+-transporting ATPase subunit a\n"
     ]
    }
   ],
   "source": [
    "print_tree(gene_subtree_dic_from_pkl['K02108'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse total structure (tree) from BR page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "from mytree import *\n",
    "\n",
    "def get_single_BR_url_from_k_page(k_url):\n",
    "    \"\"\" \n",
    "    url like https://www.kegg.jp/entry/K02703 are from \n",
    "    >>> with open(pathway_gene_name_filename, 'r') as f:\n",
    "            gene_ids = []\n",
    "            for i in f.readlines():\n",
    "                gene_ids.append(i[:6])\n",
    "        urls = []\n",
    "        prefix = 'https://www.genome.jp/entry/'\n",
    "        for i in gene_ids:\n",
    "            urls.append(prefix+i)\n",
    "    \"\"\"\n",
    "    response = requests.get(k_url)\n",
    "    webpage = response.content\n",
    "    gene_id = k_url[-6:]\n",
    "\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    for i in soup.find_all('span'):\n",
    "        if '\\xa0'+gene_id in i.text:\n",
    "            target = i\n",
    "    pattern = re.compile(r'BR:<a href=\"(.+?)\"')\n",
    "    links = pattern.findall(str(target))\n",
    "    return links\n",
    "\n",
    "def parse_BR_tree(data):\n",
    "    node = TreeNode(data.get('values', None))\n",
    "    for child_data in data.get('children', []):\n",
    "        child_node = parse_BR_tree(child_data)\n",
    "        node.children.append(child_node)\n",
    "    return node\n",
    "\n",
    "def clean_br_tree_dic(node):\n",
    "    # Basically convert lists in value into strings\n",
    "    if 'values' in node:\n",
    "        if isinstance(node['values'], list):\n",
    "            node['values'] = ''.join(node['values'])\n",
    "    \n",
    "    if 'children' in node:\n",
    "        for child in node['children']:\n",
    "            clean_br_tree_dic(child)\n",
    "\n",
    "def get_total_BR_link_tuple(urls):\n",
    "    br_links = set()\n",
    "    prefix = \"https://www.genome.jp\"\n",
    "    for i in tqdm(urls):\n",
    "        tmp_links = get_single_BR_url_from_k_page(i)\n",
    "        for j in tmp_links:\n",
    "            tmp_full_link = prefix + j\n",
    "            br_links.add(tmp_full_link)\n",
    "\n",
    "    total_BR_link = set()\n",
    "    for i in br_links:\n",
    "        total_BR_link.add(i[:-7])\n",
    "    \n",
    "    return br_links, total_BR_link\n",
    "\n",
    "def get_total_BR_tree_dic(br_hierarchy_link):\n",
    "    max_attempts = 5\n",
    "    total_BR_tree_dic = dict()\n",
    "    \n",
    "    for i in tqdm(list(br_hierarchy_link)):\n",
    "        current_attempt = 1\n",
    "        name = i[-7:]\n",
    "        while current_attempt <= max_attempts:\n",
    "            try:\n",
    "                br_tree = _get_single_BR_tree(i)\n",
    "                total_BR_tree_dic[name] = br_tree\n",
    "                break  # Exit the loop if the function runs without errors\n",
    "            except Exception as e:\n",
    "                print(f\"Attempt {current_attempt}: An error occurred - {str(e)}\")\n",
    "                time.sleep(1)\n",
    "                current_attempt += 1\n",
    "\n",
    "        if current_attempt > max_attempts:\n",
    "            print(f\"Max attempts reached. Function execution failed on page {i}.\")\n",
    "    \n",
    "    return total_BR_tree_dic\n",
    "\n",
    "def _get_single_BR_tree(br_url='https://www.genome.jp/brite/ko00194'):\n",
    "    br_page = requests.get(br_url)\n",
    "    soup = BeautifulSoup(br_page.content, 'html.parser')\n",
    "    raw = str(soup.find_all('script')[-1]).split('\\n')[1][13:]\n",
    "    dic_text = re.sub(r'<a href=.*?>(.*?)</a>', r'\\1', raw)\n",
    "    dic_text = re.sub(r' \\[EC:[^\\]]*\\]', '', dic_text)\n",
    "    replace_list = ['\"expanded\":false,', ',\"expanded\":false',\n",
    "            '\"expanded\":true,', ',\"expanded\":true',\n",
    "            '\"expanded\":true,', ',\"expanded\":true', ',\"isRoot\":true', '\"isRoot\":true,', '<b>', '</b>',\n",
    "            ',\"devMode\":false', ',\"columnWidth\":[]', ',\"visibleIndentHandle\":false', ',\"columnTitle\":[\"Chaperone\"]',\n",
    "            ',\"org\":\"ko\"', ',\"isIndexFile\":false', ',\"joinPruningQuery\":[]', ',\"alignTerminalNode\":false',\n",
    "            ',\"zoomout\":null', ',\"highlight\":{}', ',\"joinPruningColumn\":[]'\n",
    "            ',\"htextNo\":\"03110\"']\n",
    "    for i in replace_list:\n",
    "        dic_text = dic_text.replace(i, '')\n",
    "\n",
    "    dic_text = dic_text.replace('\"values\":[]', '\"values\": None').replace('\"values\": []', '\"values\": None')\n",
    "    tree_dic = eval(dic_text)\n",
    "    tree_dic = tree_dic['root']\n",
    "\n",
    "    clean_br_tree_dic(tree_dic)\n",
    "    br_tree = parse_BR_tree(tree_dic)\n",
    "    \n",
    "    return br_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: An error occurred - name 'false' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:06<00:02,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: An error occurred - name 'null' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.56s/it]\n"
     ]
    }
   ],
   "source": [
    "br_links, total_BR_link = get_total_BR_link_tuple(urls)\n",
    "br_links_tuple = br_links, total_BR_link\n",
    "with open(\"br_links_tuple.pkl\", 'wb') as p:\n",
    "    pickle.dump(br_links_tuple, p)\n",
    "\n",
    "# Here we get four total_BR_tree_dic\n",
    "total_BR_tree_dic = get_total_BR_tree_dic(br_links_tuple[1])\n",
    "with open(\"total_BR_tree_dic.pkl\", 'wb') as p:\n",
    "    pickle.dump(total_BR_tree_dic, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1: An error occurred - name 'null' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:20<00:00, 20.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Here we load the total_BR_tree_dic of human\n",
    "br_hierarchy_link = 'https://www.kegg.jp/brite/hsa00001'\n",
    "human_dic = get_total_BR_tree_dic([br_hierarchy_link])\n",
    "\n",
    "with open(\"human_total_BR_tree_dic.pkl\", 'wb') as p:\n",
    "    pickle.dump(human_dic, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_hierarchy_link = 'https://www.kegg.jp/brite/hsa00001'\n",
    "br_page = requests.get(br_hierarchy_link)\n",
    "soup = BeautifulSoup(br_page.content, 'html.parser')\n",
    "raw = str(soup.find_all('script')[-1]).split('\\n')[1][13:]\n",
    "dic_text = re.sub(r'<a href=.*?>(.*?)</a>', r'\\1', raw)\n",
    "dic_text = re.sub(r' \\[EC:[^\\]]*\\]', '', dic_text)\n",
    "replace_list = ['\"expanded\":false,', ',\"expanded\":false',\n",
    "        '\"expanded\":true,', ',\"expanded\":true',\n",
    "        '\"expanded\":true,', ',\"expanded\":true', ',\"isRoot\":true', '\"isRoot\":true,', '<b>', '</b>',\n",
    "        ',\"devMode\":false', ',\"columnWidth\":[]', ',\"visibleIndentHandle\":false', ',\"columnTitle\":[\"Chaperone\"]',\n",
    "        ',\"org\":\"ko\"', ',\"isIndexFile\":false', ',\"joinPruningQuery\":[]', ',\"alignTerminalNode\":false',\n",
    "        ',\"zoomout\":null', ',\"highlight\":{}', ',\"joinPruningColumn\":[]'\n",
    "        ',\"htextNo\":\"03110\"']\n",
    "for i in replace_list:\n",
    "    dic_text = dic_text.replace(i, '')\n",
    "\n",
    "dic_text = dic_text.replace('\"values\":[]', '\"values\": None').replace('\"values\": []', '\"values\": None')\n",
    "tree_dic = eval(dic_text)\n",
    "tree_dic = tree_dic['root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_hierarchy_link = 'https://www.genome.jp/brite/ko00194'\n",
    "br_page = requests.get(br_hierarchy_link)\n",
    "soup = BeautifulSoup(br_page.content, 'html.parser')\n",
    "raw = str(soup.find_all('script')[-1]).split('\\n')[1][13:]\n",
    "dic_text = re.sub(r'<a href=.*?>(.*?)</a>', r'\\1', raw)\n",
    "dic_text = re.sub(r' \\[EC:[^\\]]*\\]', '', dic_text)\n",
    "replace_list = ['\"expanded\":false,', ',\"expanded\":false',\n",
    "        '\"expanded\":true,', ',\"expanded\":true',\n",
    "        '\"expanded\":true,', ',\"expanded\":true', ',\"isRoot\":true', '\"isRoot\":true,', '<b>', '</b>',\n",
    "        ',\"devMode\":false', ',\"columnWidth\":[]', ',\"visibleIndentHandle\":false', ',\"columnTitle\":[\"Chaperone\"]',\n",
    "        ',\"org\":\"ko\"', ',\"isIndexFile\":false', ',\"joinPruningQuery\":[]', ',\"alignTerminalNode\":false',\n",
    "        ',\"zoomout\":null', ',\"highlight\":{}', ',\"joinPruningColumn\":[]'\n",
    "        ',\"htextNo\":\"03110\"']\n",
    "for i in replace_list:\n",
    "    dic_text = dic_text.replace(i, '')\n",
    "\n",
    "dic_text = dic_text.replace('\"values\":[]', '\"values\": None').replace('\"values\": []', '\"values\": None')\n",
    "tree_dic = eval(dic_text)\n",
    "tree_dic = tree_dic['root']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
